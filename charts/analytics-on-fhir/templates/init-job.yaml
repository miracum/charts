apiVersion: batch/v1
kind: Job
metadata:
  name: init
spec:
  ttlSecondsAfterFinished: 100
  template:
    spec:
      automountServiceAccountToken: false
      initContainers:
        - name: download-clis
          image: docker.io/curlimages/curl:8.16.0@sha256:463eaf6072688fe96ac64fa623fe73e1dbe25d8ad6c34404a669ad3ce1f104b6
          command: ["/bin/sh", "-c"]
          workingDir: /downloads
          args:
            - |
              curl -LO https://github.com/synthetichealth/synthea/releases/download/master-branch-latest/synthea-with-dependencies.jar
              curl -LO https://dl.min.io/client/mc/release/linux-amd64/mc
              chmod +x mc
          volumeMounts:
            - name: downloads
              mountPath: /downloads
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 2Gi
              memory: 128Mi
        - name: wait-for-pathling-server
          image: docker.io/curlimages/curl:8.16.0@sha256:463eaf6072688fe96ac64fa623fe73e1dbe25d8ad6c34404a669ad3ce1f104b6
          command: ["/bin/sh", "-c"]
          env:
            - name: PATHLING_URL
              value: http://aof-pathling-server:8080
          args:
            - |
              until [ "$(curl -s -o /dev/null -L -w "%{http_code}" "$$PATHLING_URL/fhir/metadata")" == "200" ]; do
                  echo "$(date): Waiting for pathling server @ $$PATHLING_URL to be up";
                  sleep 5;
              done;
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 50Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
        - name: wait-for-hive-metastore
          image: ghcr.io/wait4x/wait4x:3.5.1@sha256:52e6791d4d8b8c80b2106e4d4f1e44ee69477c6dd461bdeb1aae2db6ccd5d038
          args:
            - tcp
            - aof-hive-metastore:9083
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 50Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
        - name: generate-and-upload-resources
          # might as well use this image since it has java installed
          image: ghcr.io/bzkf/fhir-to-lakehouse:v1.13.1@sha256:5dee865c98853782bb61784a041ecd349210b406bd0cd720c73f8c2a29571cad
          command: ["/bin/sh", "-c"]
          workingDir: /downloads
          env:
            - name: SYNTHEA_SEED
              value: "20250916"
            - name: AWS_ENDPOINT_URL_S3
              value: http://aof-minio:9000
            - name: MINIO_UPDATE
              value: "off"
            - name: MINIO_CALLHOME_ENABLE
              value: "off"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aof-minio
                  key: root-user
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aof-minio
                  key: root-password
          args:
            - |
              java -jar /downloads/synthea-with-dependencies.jar -s $SYNTHEA_SEED -cs $SYNTHEA_SEED -r $SYNTHEA_SEED -p 250 -c /tmp/config/synthea.properties
              /downloads/mc alias set minio "${AWS_ENDPOINT_URL_S3}" "${AWS_ACCESS_KEY_ID}" "${AWS_SECRET_ACCESS_KEY}"
              /downloads/mc mb --ignore-existing minio/import
              /downloads/mc cp --recursive /downloads/synthea/ minio/import/
          volumeMounts:
            - name: downloads
              mountPath: /downloads
            - name: init-job-config
              mountPath: /tmp/config
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 2000m
              ephemeral-storage: 2Gi
              memory: 2Gi
            requests:
              cpu: 100m
              ephemeral-storage: 2Gi
              memory: 2Gi
        - name: bulk-import
          image: docker.io/curlimages/curl:8.16.0@sha256:463eaf6072688fe96ac64fa623fe73e1dbe25d8ad6c34404a669ad3ce1f104b6
          env:
            - name: PATHLING_URL
              value: http://aof-pathling-server:8080
          command: ["/bin/sh", "-c"]
          args:
            - |
              curl --fail -X POST --header 'Content-Type: application/fhir+json' --data @/tmp/config/import-request.json --url '$PATHLING_URL/$$import'
          volumeMounts:
            - name: init-job-config
              mountPath: /tmp/config
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 50Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
      containers:
        - name: lakehousekeeper
          image: ghcr.io/bzkf/fhir-to-lakehouse:v1.13.1@sha256:5dee865c98853782bb61784a041ecd349210b406bd0cd720c73f8c2a29571cad
          env:
            - name: HIVE_METASTORE_URI
              value: thrift://aof-hive-metastore:9083
          command: ["/bin/sh", "-c"]
          args:
            - |
              python3 /app/src/lakehousekeeper.py register --bucket-name=fhir --database-name-prefix=default/ --hive-metastore=${HIVE_METASTORE_URI}
              python3 /app/src/lakehousekeeper.py optimize --bucket-name=fhir --database-name-prefix=default/
              python3 /app/src/lakehousekeeper.py vacuum   --bucket-name=fhir --database-name-prefix=default/ --retention-hours=0 --dry-run=false --enforce-retention-duration=false
          volumeMounts:
            - name: init-job-config
              mountPath: /app/spark/conf
              subPath: spark-defaults.conf
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 2Gi
              memory: 128Mi
      restartPolicy: Never
      volumes:
        - name: downloads
          emptyDir: {}
        - name: init-job-config
          configMap:
            name: init-job-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: init-job-config
data:
  spark-defaults.conf: |
      spark.driver.memory=4g
  synthea.properties: |
    exporter.fhir.export = true
    exporter.hospital.fhir.export = true
    exporter.practitioner.fhir.export = true
    exporter.fhir.included_resources = Patient,Observation,Condition
    exporter.fhir.bulk_data = true
    exporter.baseDirectory = ./synthea/
  import-request.json: |
    {
        "resourceType": "Parameters",
        "parameter": [
            {
                "name": "source",
                "part": [
                    {
                        "name": "resourceType",
                        "valueCode": "Patient"
                    },
                    {
                        "name": "url",
                        "valueUrl": "s3a://import/Patient.ndjson"
                    },
                    {
                        "name": "mode",
                        "valueCode": "overwrite"
                    }
                ]
            },
            {
                "name": "source",
                "part": [
                    {
                        "name": "resourceType",
                        "valueCode": "Condition"
                    },
                    {
                        "name": "url",
                        "valueUrl": "s3a://import/Condition.ndjson"
                    },
                    {
                        "name": "mode",
                        "valueCode": "overwrite"
                    }
                ]
            },
            {
                "name": "source",
                "part": [
                    {
                        "name": "resourceType",
                        "valueCode": "Observation"
                    },
                    {
                        "name": "url",
                        "valueUrl": "s3a://import/Observation.ndjson"
                    },
                    {
                        "name": "mode",
                        "valueCode": "overwrite"
                    }
                ]
            }
        ]
    }
